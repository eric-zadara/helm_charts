# Inference operators umbrella chart

# cert-manager - TLS certificate management operator
cert-manager:
  # -- Enable cert-manager deployment
  enabled: true
  # Install CRDs with the chart
  crds:
    enabled: true

# CloudNativePG operator - PostgreSQL operator for Kubernetes
cloudnative-pg:
  # -- Enable CNPG operator deployment
  enabled: true

# KServe controller - reconciles InferenceService, ClusterServingRuntime resources
kserve:
  # -- Enable KServe controller deployment
  enabled: true
  kserve:
    controller:
      # Use Knative deployment mode (v0.16.0 renamed "Serverless" to "Knative")
      deploymentMode: "Knative"
      resources:
        limits:
          cpu: 100m
          memory: 300Mi
        requests:
          cpu: 100m
          memory: 300Mi
    # Disable ALL built-in ClusterServingRuntimes
    # This project provides its own runtimes via model-serving chart (vLLM, llama.cpp, Ollama)
    servingruntime:
      tensorflow:
        disabled: true
      mlserver:
        disabled: true
      sklearnserver:
        disabled: true
      xgbserver:
        disabled: true
      huggingfaceserver:
        disabled: true
      tritonserver:
        disabled: true
      pmmlserver:
        disabled: true
      paddleserver:
        disabled: true
      lgbserver:
        disabled: true
      torchserve:
        disabled: true
    # Disable features not needed for this project
    localmodel:
      enabled: false

# Knative Operator - manages Knative Serving/Eventing via CRs
knative-operator:
  # -- Enable Knative Operator deployment
  enabled: true

# Envoy Gateway - Gateway API controller
envoy-gateway:
  # -- Enable Envoy Gateway deployment
  enabled: true

# NVIDIA GPU Operator - manages GPU device plugin, runtime, monitoring
gpu-operator:
  # -- Enable NVIDIA GPU Operator deployment
  enabled: true
  # Skip driver installation (pre-installed on GPU VMs)
  driver:
    enabled: false
