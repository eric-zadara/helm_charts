# CI test values for model-serving chart
# Minimal overlay on production defaults -- only override what differs for CI.
# Prerequisites: tier1-crds (Gateway API, Inference Extension, KServe CRDs)

# ClusterServingRuntimes - ENABLED (KServe controller deployed by inference-operators)
# These reconcile immediately without starting any pods.
# Production defaults (enabled: true) are used -- no override needed.

# InferenceServices - DISABLED (require actual model serving pods, GPUs, storage)
# Even with KServe controller running, these create pods that need real infrastructure.
# This is a permanent CI limitation, not a TODO.
inferenceService:
  enabled: false
llamacppInferenceService:
  enabled: false
ollamaInferenceService:
  enabled: false

# InferencePool - enabled (inference-extension-crds available from tier1-crds)
# Not enabled in prod defaults, but testable with CRDs alone.
inferencePool:
  enabled: true

# InferenceObjective - enabled (inference-extension-crds available)
inferenceObjective:
  enabled: true

# HTTPRoute for InferencePool - enabled (gateway-api CRDs available)
inferencePoolRoute:
  enabled: true

# PriorityClasses - standard K8s resources, not enabled in prod defaults
priorityClasses:
  enabled: true

# HuggingFace secret - test with dummy token
huggingface:
  secretEnabled: true
  token: "test-token-for-ci"

# S3 storage - test with dummy credentials
s3Storage:
  enabled: true
  accessKeyId: "test-access-key"
  secretAccessKey: "test-secret-key"
