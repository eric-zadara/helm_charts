apiVersion: v2
name: inference-infrastructure
description: Infrastructure layer for LLM inference platform - databases, networking, and API proxy
type: application
version: 0.5.0
appVersion: "1.0.0"
annotations:
  testing/tier: "3"
  testing/prerequisites: "tier1-crds,cnpg-operator"

# Umbrella chart that bundles infrastructure components:
# - PostgreSQL cluster (CNPG) - enabled by default
# - Valkey cache - enabled by default
# - Networking layer (Envoy Gateway + Kourier)
# - LiteLLM API proxy (auto-wired to PostgreSQL/Valkey)

dependencies:
  # CNPG PostgreSQL cluster
  - name: cluster
    version: "0.5.0"
    repository: https://cloudnative-pg.github.io/charts
    alias: postgresql
    condition: postgresql.enabled

  # Valkey cache (official chart)
  - name: valkey
    version: "0.9.3"
    repository: https://valkey.io/valkey-helm/
    condition: valkey.enabled

  # Envoy Gateway + Kourier networking
  - name: networking-layer
    version: "0.2.0"
    repository: "https://eric-zadara.github.io/helm_charts/"
    condition: networking-layer.enabled

  # LiteLLM multi-tenant API proxy
  - name: litellm-proxy
    version: "0.1.0"
    repository: "https://eric-zadara.github.io/helm_charts/"
    condition: litellm-proxy.enabled
